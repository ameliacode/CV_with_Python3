{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 💻 신경망을 이용한 이미지 분류\n",
    "신경망을 통해 더 정교하고 정확도가 더 높은 머신러닝으로 이미지를 분류한다.\n",
    "\n",
    "### 신경망 소개\n",
    "신경망은 기본적으로 퍼셉트론(뉴런)으로 구성되어 있다.  \n",
    "가장 일반적으로 각 입력에 가중치가 곱해지고 모든 곱의 합이 정규화되어서 출력된다.\n",
    "기본적으로 퍼셉트론은 입력 세트를 입력 레이어(첫 번째 레이어)에서 고 퍼셉트론의 히든 레이어에서 연산후 다음 레이어로 출력(출력 레이어)을 반환한다. 이 때 입력 레이어에 비해 히든 레이어에 비해 크거나 작지 않아야하며, 출력 레이어의 크기는 레이블의 수에 따라 달라진다. 즉, 출력 레이어는 각 레이블에 해당하는 퍼셉트론을 갖는다.  \n",
    "#### 네트워크 학습\n",
    "네트워크 학습 시에는 크게 두 단계로 나눌 수 있다. 첫 번째는 입력을 앞으로 전달하여 입력 값에 퍼셉트론의 가중치를 곱하고 출력이 생성되는 과정, 그리고 출력과 실제 출력의 오차를 이용의 퍼셉트론의 가중치를 수정하는 역전파 과정으로 나뉘어 진다. 이 과정을 여러번 전달하게 되는데, 모든 데이터를 한 번 전달하는 것을 세대(epoch)라고 한다.\n",
    "\n",
    "### 신경망을 이용한 MNIST 숫자 분류\n",
    "1. 이미지 픽셀 값을 0,1 혹은 -1,1 사이로 정규화하여 전처리\n",
    "2. 학습 세트와 테스트 세트로 데이터 세트를 나눈다.\n",
    "3. 학습 데이터 세트로 학습\n",
    "4. 테스트 데이터 세트로 네트워크의 성능을 확인한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting MNIST Data...\n",
      "MNIST Data downloaded!\n"
     ]
    }
   ],
   "source": [
    "print(\"Getting MNIST Data...\")\n",
    "mnist = fetch_openml('mnist_784', version=1, cache=True)\n",
    "print(\"MNIST Data downloaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = mnist.data\n",
    "labels = mnist.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = normalize(images,  norm =\"l2\") #정규화\n",
    "images_train, images_test, labels_train, labels_test = train_test_split(images, #학습/테스트 데이터 분할\n",
    "                                                                        labels, \n",
    "                                                                        test_size=0.25, \n",
    "                                                                        random_state=17) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = MLPClassifier(hidden_layer_sizes=(100,100,100), #네트워크 크기\n",
    "                   max_iter = 20,            #학습을 수행할 최대 반복 횟수 설정\n",
    "                   solver = \"sgd\", \n",
    "                   learning_rate_init=0.001,\n",
    "                   verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN Training started...\n",
      "Iteration 1, loss = 2.30784965\n",
      "Iteration 2, loss = 2.28616402\n",
      "Iteration 3, loss = 2.26857418\n",
      "Iteration 4, loss = 2.24496765\n",
      "Iteration 5, loss = 2.20764662\n",
      "Iteration 6, loss = 2.14426503\n",
      "Iteration 7, loss = 2.03160676\n",
      "Iteration 8, loss = 1.84484981\n",
      "Iteration 9, loss = 1.60323469\n",
      "Iteration 10, loss = 1.37186946\n",
      "Iteration 11, loss = 1.17817786\n",
      "Iteration 12, loss = 1.02171217\n",
      "Iteration 13, loss = 0.90567090\n",
      "Iteration 14, loss = 0.82203268\n",
      "Iteration 15, loss = 0.75835112\n",
      "Iteration 16, loss = 0.70600132\n",
      "Iteration 17, loss = 0.66164720\n",
      "Iteration 18, loss = 0.62323073\n",
      "Iteration 19, loss = 0.58935911\n",
      "Iteration 20, loss = 0.55952842\n",
      "NN Training completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print(\"NN Training started...\")\n",
    "nn.fit(images_train, labels_train)\n",
    "print(\"NN Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network Performance: 0.843429\n"
     ]
    }
   ],
   "source": [
    "print(\"Network Performance: %f\" %nn.score(images_test, labels_test) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 합성곱 신경망(Convolutional Neural Network)\n",
    "기본적으로 합성곱은 커널/필터를 적용시켜 원래 이미지보다 작을 수 있는 새로운 이미지를 만드는 연산이다. CNN에서는 입력 이미지를 시작으로 매번 이미지를 받고 필터를 사용해 합성곱을 적용한다. 따라서 매 합성곱 레이어 이후 출력 이미지는 입력 이미지보다 현저히 작으며 이를 subsampling이라고 한다.   \n",
    "<img src = \"cnn.png\" width=\"800\">  \n",
    "합성곱 사이에서 서브샘플링으로 레이어는 완전히 연결되어 있다 = fully connected layer. FC 레이어에서는 서브샘플링된 이미지를 각각 레이블에 대한 점수 값으로 변환이 되고, 각 출력 값은 각 클래스에 대한 확률 값이다.  \n",
    "👇🏻  아래 코드는 전통 CNN의 종류인 LeNet을 구현한 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D\n",
    "from tensorflow.keras.layers import Activation, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras import utils\n",
    "from sklearn import datasets\n",
    "from tensorflow.keras import backend as k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "k.set_image_data_format(\"channels_first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes=10\n",
    "img_depth=1\n",
    "img_height=28\n",
    "img_width=28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(20, (5,5), input_shape=(img_depth, img_height, img_width)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())\n",
    "model.add(Dense(500))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation(\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = fetch_openml('mnist_784', version=1, cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist.data = mnist.data.reshape((mnist.data.shape[0], 28,28))\n",
    "mnist.data = mnist.data[:,np.newaxis,:,:]\n",
    "mnist.data = mnist.data/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, train_label, test_label = train_test_split(mnist.data,\n",
    "                                                                 mnist.target,\n",
    "                                                                 test_size=0.25)\n",
    "train_label = utils.to_categorical(train_label, 10)\n",
    "test_label = utils.to_categorical(test_label, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1641/1641 [==============================] - 5s 3ms/step - loss: 1.5244 - accuracy: 0.6584\n",
      "Epoch 2/30\n",
      "1641/1641 [==============================] - 5s 3ms/step - loss: 0.5023 - accuracy: 0.8715\n",
      "Epoch 3/30\n",
      "1641/1641 [==============================] - 5s 3ms/step - loss: 0.3717 - accuracy: 0.8957\n",
      "Epoch 4/30\n",
      "1641/1641 [==============================] - 5s 3ms/step - loss: 0.3242 - accuracy: 0.9081\n",
      "Epoch 5/30\n",
      "1641/1641 [==============================] - 5s 3ms/step - loss: 0.2955 - accuracy: 0.9154\n",
      "Epoch 6/30\n",
      "1641/1641 [==============================] - 5s 3ms/step - loss: 0.2748 - accuracy: 0.9211\n",
      "Epoch 7/30\n",
      "1641/1641 [==============================] - 5s 3ms/step - loss: 0.2575 - accuracy: 0.9265\n",
      "Epoch 8/30\n",
      "1641/1641 [==============================] - 5s 3ms/step - loss: 0.2431 - accuracy: 0.9300\n",
      "Epoch 9/30\n",
      "1641/1641 [==============================] - 5s 3ms/step - loss: 0.2303 - accuracy: 0.9337\n",
      "Epoch 10/30\n",
      "1641/1641 [==============================] - 5s 3ms/step - loss: 0.2187 - accuracy: 0.9375\n",
      "Epoch 11/30\n",
      "1641/1641 [==============================] - 5s 3ms/step - loss: 0.2084 - accuracy: 0.9400\n",
      "Epoch 12/30\n",
      "1641/1641 [==============================] - 5s 3ms/step - loss: 0.1985 - accuracy: 0.9434\n",
      "Epoch 13/30\n",
      "1641/1641 [==============================] - 5s 3ms/step - loss: 0.1898 - accuracy: 0.9458\n",
      "Epoch 14/30\n",
      "1641/1641 [==============================] - 5s 3ms/step - loss: 0.1819 - accuracy: 0.9480\n",
      "Epoch 15/30\n",
      "1641/1641 [==============================] - 5s 3ms/step - loss: 0.1743 - accuracy: 0.9505\n",
      "Epoch 16/30\n",
      "1641/1641 [==============================] - 5s 3ms/step - loss: 0.1675 - accuracy: 0.9516\n",
      "Epoch 17/30\n",
      "1641/1641 [==============================] - 5s 3ms/step - loss: 0.1612 - accuracy: 0.9536\n",
      "Epoch 18/30\n",
      "1641/1641 [==============================] - 5s 3ms/step - loss: 0.1554 - accuracy: 0.9558\n",
      "Epoch 19/30\n",
      "1641/1641 [==============================] - 5s 3ms/step - loss: 0.1497 - accuracy: 0.9571\n",
      "Epoch 20/30\n",
      "1641/1641 [==============================] - 5s 3ms/step - loss: 0.1448 - accuracy: 0.9587\n",
      "Epoch 21/30\n",
      "1641/1641 [==============================] - 5s 3ms/step - loss: 0.1397 - accuracy: 0.9602\n",
      "Epoch 22/30\n",
      "1641/1641 [==============================] - 5s 3ms/step - loss: 0.1353 - accuracy: 0.9615\n",
      "Epoch 23/30\n",
      "1641/1641 [==============================] - 5s 3ms/step - loss: 0.1309 - accuracy: 0.9631\n",
      "Epoch 24/30\n",
      "1641/1641 [==============================] - 5s 3ms/step - loss: 0.1272 - accuracy: 0.9635\n",
      "Epoch 25/30\n",
      "1641/1641 [==============================] - 5s 3ms/step - loss: 0.1235 - accuracy: 0.9647\n",
      "Epoch 26/30\n",
      "1641/1641 [==============================] - 5s 3ms/step - loss: 0.1200 - accuracy: 0.9659\n",
      "Epoch 27/30\n",
      "1641/1641 [==============================] - 5s 3ms/step - loss: 0.1164 - accuracy: 0.9663\n",
      "Epoch 28/30\n",
      "1641/1641 [==============================] - 5s 3ms/step - loss: 0.1132 - accuracy: 0.9675\n",
      "Epoch 29/30\n",
      "1641/1641 [==============================] - 5s 3ms/step - loss: 0.1102 - accuracy: 0.9688\n",
      "Epoch 30/30\n",
      "1641/1641 [==============================] - 5s 3ms/step - loss: 0.1072 - accuracy: 0.9694\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1928354f9a0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer = SGD(lr=0.001),\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_data,train_label,batch_size=32, epochs=30, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 1s 3ms/step - loss: 0.1210 - accuracy: 0.9645\n",
      "Accuracy: % 96.45143151283264\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_data,test_label, batch_size=64,verbose=1)\n",
    "print(\"Accuracy: %\",format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 머신러닝의 난제\n",
    "좋은 데이터, 데이터의 수(충분한가?) 그리고 좋은 알고리즘"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
